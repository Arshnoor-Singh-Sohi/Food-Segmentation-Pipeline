#!/usr/bin/env python3
"""
FIXED Food Model Training Orchestrator
Now actually creates training data instead of empty directories!

Usage:
    python scripts/train_custom_food_model.py --mode check_setup
    python scripts/train_custom_food_model.py --mode quick_test
    python scripts/train_custom_food_model.py --mode full_training --epochs 50
"""

import sys
import argparse
from pathlib import Path
import yaml
import time
from datetime import datetime

# Add project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Import the FIXED training modules
from src.training.food_dataset_preparer import FoodDatasetPreparer
from src.training.food_yolo_trainer import FoodYOLOTrainer

class TrainingOrchestrator:
    """
    FIXED Training Orchestrator - Now creates real training data!
    """
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.start_time = datetime.now()
        
        print("üçï Food Model Training Orchestrator (FIXED VERSION)")
        print("=" * 60)
        print(f"üìÅ Project root: {self.project_root}")
        print(f"üïê Started at: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    def check_setup(self):
        """
        NEW: Check if everything is ready for training
        This helps identify issues before starting training
        """
        print("\nüîç CHECKING TRAINING SETUP")
        print("Verifying that everything is ready for training...")
        print("-" * 50)
        
        setup_ok = True
        
        # Check 1: Input images exist
        input_dir = Path("data/input")
        if not input_dir.exists():
            print("‚ùå data/input directory not found")
            print("üí° Create it with: mkdir -p data/input")
            setup_ok = False
        else:
            # Count images
            image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
            image_files = []
            for ext in image_extensions:
                image_files.extend(list(input_dir.glob(f"*{ext}")))
                image_files.extend(list(input_dir.glob(f"*{ext.upper()}")))
            
            if len(image_files) == 0:
                print(f"‚ùå No images found in {input_dir}")
                print("üí° Add some food images to data/input/ directory")
                setup_ok = False
            else:
                print(f"‚úÖ Found {len(image_files)} images in {input_dir}")
                print(f"   Sample images: {', '.join([f.name for f in image_files[:3]])}")
        
        # Check 2: Required directories exist
        required_dirs = [
            "src/training",
            "data/training",
            "config"
        ]
        
        for dir_path in required_dirs:
            if not Path(dir_path).exists():
                print(f"‚ùå Missing directory: {dir_path}")
                print(f"üí° Create it with: mkdir -p {dir_path}")
                setup_ok = False
            else:
                print(f"‚úÖ Directory exists: {dir_path}")
        
        # Check 3: Configuration files
        config_file = Path("config/training_config.yaml")
        if not config_file.exists():
            print(f"‚ùå Missing config file: {config_file}")
            print("üí° Run the setup script first: python setup_training.py")
            setup_ok = False
        else:
            print(f"‚úÖ Config file exists: {config_file}")
        
        # Check 4: Python packages
        try:
            import ultralytics
            print("‚úÖ ultralytics package available")
        except ImportError:
            print("‚ùå ultralytics package not found")
            print("üí° Install with: pip install ultralytics")
            setup_ok = False
        
        try:
            import torch
            device_info = "GPU available" if torch.cuda.is_available() else "CPU only"
            print(f"‚úÖ PyTorch available ({device_info})")
        except ImportError:
            print("‚ùå PyTorch not found")
            print("üí° Install with: pip install torch torchvision")
            setup_ok = False
        
        # Final verdict
        print("\n" + "=" * 50)
        if setup_ok:
            print("üéâ SETUP CHECK PASSED!")
            print("‚úÖ Everything looks good - ready for training!")
            print("\nüí° Next step: python scripts/train_custom_food_model.py --mode quick_test")
        else:
            print("üö® SETUP CHECK FAILED!")
            print("‚ùå Please fix the issues above before training")
            print("\nüí° After fixing issues, run this check again")
        
        return setup_ok
    
    def quick_test_training(self, epochs=5):
        """
        FIXED: Run quick test with actual training data
        
        Args:
            epochs: Number of epochs (reduced to 5 for faster testing)
        """
        print(f"\nüöÄ QUICK TEST TRAINING - {epochs} EPOCHS")
        print("Creating real training data and training for a few epochs")
        print("This validates your setup before longer training runs")
        print("-" * 50)
        
        # Step 1: Check setup first
        print("üîç Step 1: Checking setup...")
        if not self.check_setup():
            print("‚ùå Setup check failed. Please fix issues first.")
            return None, None
        
        # Step 2: Create real training dataset
        print("\nüì¶ Step 2: Creating training dataset with REAL data...")
        preparer = FoodDatasetPreparer()
        
        # Use the FIXED method that creates actual training data
        dataset_yaml, food_categories = preparer.create_sample_dataset_with_real_data(
            source_dir="data/input",
            num_classes=1  # Start with just one class: "food"
        )
        
        if dataset_yaml is None:
            print("‚ùå Failed to create dataset. Check that you have images in data/input/")
            return None, None
        
        print(f"‚úÖ Created dataset with {len(food_categories)} categories:")
        print(f"   {', '.join(food_categories)}")
        
        # Step 3: Validate the dataset
        print("\nüîç Step 3: Validating dataset...")
        validation = preparer.validate_dataset(dataset_yaml)
        
        if not validation['valid']:
            print("‚ùå Dataset validation failed!")
            return None, None
        
        # Step 4: Quick training run
        print(f"\nüèãÔ∏è  Step 4: Training for {epochs} epochs...")
        trainer = FoodYOLOTrainer(dataset_yaml)
        
        try:
            model, results = trainer.train_food_detector(
                epochs=epochs,
                custom_name=f"quick_test_{datetime.now().strftime('%m%d_%H%M')}"
            )
            
            print("‚úÖ Training completed successfully!")
            
            # Step 5: Quick validation
            print("\nüß™ Step 5: Testing the trained model...")
            validation_results = trainer.validate_model(
                "data/models/custom_food_detection.pt",
                "data/input"
            )
            
            self._print_quick_results(validation_results, epochs)
            
            print("\nüéâ Quick test training completed successfully!")
            print("üí° Your setup is working! Try full training for better results.")
            
            return model, results
            
        except Exception as e:
            print(f"‚ùå Training failed with error: {e}")
            print("üí° This might be due to insufficient training data or configuration issues")
            return None, None
    
    def full_training(self, epochs=50, dataset_type="smart"):
        """
        FIXED: Run full training with proper dataset creation
        
        Args:
            epochs: Number of training epochs
            dataset_type: Type of dataset ('smart' uses existing images intelligently)
        """
        print(f"\nüéØ FULL TRAINING - {epochs} EPOCHS")
        print("Training a production-ready food detection model")
        print("This will take some time but produces better results")
        print("-" * 50)
        
        # Step 1: Setup check
        print("üîç Step 1: Checking setup...")
        if not self.check_setup():
            print("‚ùå Setup check failed. Please fix issues first.")
            return None, None
        
        # Step 2: Prepare dataset
        print("\nüì¶ Step 2: Preparing training dataset...")
        preparer = FoodDatasetPreparer()
        
        if dataset_type == "smart":
            # Use the smart method that creates better automatic labels
            dataset_yaml = preparer.create_from_existing_images_smart("data/input")
            if dataset_yaml is None:
                print("‚ùå Could not prepare smart dataset from existing images")
                return None, None
            print("‚úÖ Using smart automatic labeling on your existing images")
            
        else:
            # Use the simple method
            dataset_yaml, food_categories = preparer.create_sample_dataset_with_real_data(
                source_dir="data/input",
                num_classes=1
            )
            if dataset_yaml is None:
                print("‚ùå Could not prepare dataset from existing images")
                return None, None
            print("‚úÖ Using simple automatic labeling")
        
        # Step 3: Validate dataset
        print("\nüîç Step 3: Validating dataset...")
        validation = preparer.validate_dataset(dataset_yaml)
        
        if not validation['valid']:
            print("‚ùå Dataset validation failed. Cannot proceed with training.")
            return None, None
        
        # Step 4: Run full training
        print(f"\nüèãÔ∏è  Step 4: Starting {epochs}-epoch training...")
        print("‚è∞ This will take some time. You can monitor progress in the terminal.")
        
        trainer = FoodYOLOTrainer(dataset_yaml)
        
        try:
            model, results = trainer.train_food_detector(
                epochs=epochs,
                custom_name=f"food_model_{datetime.now().strftime('%Y%m%d_%H%M')}"
            )
            
            print("‚úÖ Full training completed successfully!")
            
            # Step 5: Comprehensive validation
            print("\nüß™ Step 5: Validating trained model...")
            validation_results = trainer.validate_model(
                "data/models/custom_food_detection.pt",
                "data/input"
            )
            
            self._print_full_results(validation_results, epochs)
            
            print("\nüéâ Full training completed!")
            print("üîÑ You can now use this model in your existing pipeline")
            print("üí° Try running your enhanced_batch_tester.py with the new model")
            
            return model, results
            
        except Exception as e:
            print(f"‚ùå Training failed with error: {e}")
            print("üí° Check the error message and consider reducing epochs or batch size")
            return None, None
    
    def _print_quick_results(self, validation_results, epochs):
        """Print encouraging results from quick test"""
        if validation_results is None:
            print("‚ö†Ô∏è  No test images found for validation")
            return
            
        summary = validation_results['summary']
        
        print("üìà Quick Test Results:")
        print(f"   üìö Training epochs: {epochs}")
        print(f"   üñºÔ∏è  Tested on: {validation_results['test_images_count']} images")
        print(f"   üéØ Average detections: {summary['avg_detections_per_image']:.1f}")
        print(f"   üíØ Average confidence: {summary['avg_max_confidence']:.3f}")
        
        # Provide realistic interpretation for quick tests
        print("\nüí° Quick Test Analysis:")
        if summary['avg_max_confidence'] > 0.3:
            print("üéâ Model is learning! Confidence scores look promising.")
        else:
            print("üîÑ Low confidence is normal for quick tests with few epochs.")
            
        if summary['images_with_detections'] > 0:
            print("‚úÖ Model is detecting objects in images - training is working!")
        else:
            print("üí° No detections yet - try training for more epochs.")
            
        print("üöÄ Ready for full training with more epochs for better results!")
    
    def segmentation_training(self, epochs=50):
        """
        FIXED: Train a segmentation model for precise food boundary detection
        
        Args:
            epochs: Number of training epochs
        """
        print(f"\nüé® SEGMENTATION TRAINING - {epochs} EPOCHS")
        print("Training model for precise food boundary detection")
        print("This enables accurate portion size estimation")
        print("-" * 50)
        
        # Step 1: Setup check
        print("üîç Step 1: Checking setup...")
        if not self.check_setup():
            print("‚ùå Setup check failed. Please fix issues first.")
            return None, None
        
        # Step 2: Prepare dataset
        print("\nüì¶ Step 2: Preparing segmentation dataset...")
        preparer = FoodDatasetPreparer()
        
        # Use existing images with smart labeling
        dataset_yaml = preparer.create_from_existing_images_smart("data/input")
        if dataset_yaml is None:
            print("‚ùå Could not prepare dataset from existing images")
            return None, None
        print("‚úÖ Using smart automatic labeling for segmentation")
        
        # Step 3: Validate dataset
        print("\nüîç Step 3: Validating dataset...")
        validation = preparer.validate_dataset(dataset_yaml)
        
        if not validation['valid']:
            print("‚ùå Dataset validation failed. Cannot proceed with training.")
            return None, None
        
        # Step 4: Train segmentation model
        print(f"\nüé® Step 4: Training segmentation model for {epochs} epochs...")
        print("‚è∞ This trains a model that can outline exact food boundaries")
        
        trainer = FoodYOLOTrainer(dataset_yaml)
        
        try:
            model, results = trainer.train_food_segmentation(
                epochs=epochs,
                custom_name=f"food_segmentation_{datetime.now().strftime('%Y%m%d_%H%M')}"
            )
            
            print("‚úÖ Segmentation training completed successfully!")
            
            # Step 5: Validation
            print("\nüß™ Step 5: Testing segmentation model...")
            validation_results = trainer.validate_model(
                "data/models/custom_food_segmentation.pt",
                "data/input"
            )
            
            self._print_segmentation_results(validation_results, epochs)
            
            print("\nüéâ Segmentation training completed!")
            print("üéØ Your model can now detect precise food boundaries")
            print("üí° Great for portion size estimation and nutrition calculation")
            
            return model, results
            
        except Exception as e:
            print(f"‚ùå Segmentation training failed with error: {e}")
            print("üí° Check the error message and consider reducing epochs or batch size")
            return None, None
    
    def _print_segmentation_results(self, validation_results, epochs):
        """Print results specific to segmentation training"""
        if validation_results is None:
            print("‚ö†Ô∏è  No test images found for validation")
            return
            
        summary = validation_results['summary']
        
        print("üé® Segmentation Training Results:")
        print(f"   üìö Training epochs: {epochs}")
        print(f"   üñºÔ∏è  Tested on: {validation_results['test_images_count']} images")
        print(f"   üéØ Average detections: {summary['avg_detections_per_image']:.1f}")
        print(f"   üíØ Average confidence: {summary['avg_max_confidence']:.3f}")
        print(f"   ‚úÖ Images with detections: {summary['images_with_detections']}/{validation_results['test_images_count']}")
        
        print("\nüé® Segmentation Analysis:")
        if summary['avg_max_confidence'] > 0.6:
            print("üåü Excellent segmentation confidence! Model can create precise food outlines.")
        elif summary['avg_max_confidence'] > 0.4:
            print("üëç Good segmentation performance. Model is working well for boundaries.")
        else:
            print("üîÑ Consider training longer for better segmentation precision.")
            
        print("üí° Segmentation models are great for:")
        print("   - Precise portion size calculation")
        print("   - Accurate nutrition estimation")
        print("   - Food waste measurement")
        print("   - Advanced visual analysis")
    
    def _print_full_results(self, validation_results, epochs):
        """Print comprehensive results from full training"""
        if validation_results is None:
            print("‚ö†Ô∏è  No test images found for validation")
            return
            
        summary = validation_results['summary']
        
        print("üèÜ Full Training Results:")
        print(f"   üìö Training epochs: {epochs}")
        print(f"   üñºÔ∏è  Tested on: {validation_results['test_images_count']} images")
        print(f"   üéØ Average detections: {summary['avg_detections_per_image']:.1f}")
        print(f"   üíØ Average confidence: {summary['avg_max_confidence']:.3f}")
        print(f"   ‚úÖ Images with detections: {summary['images_with_detections']}/{validation_results['test_images_count']}")
        
        # Performance interpretation
        print("\nüìä Performance Analysis:")
        
        if summary['avg_max_confidence'] > 0.6:
            print("üåü Excellent confidence scores! Model is production-ready.")
        elif summary['avg_max_confidence'] > 0.4:
            print("üëç Good confidence scores. Model is working well.")
        else:
            print("üîÑ Consider training longer or adding more varied training data.")
            
        detection_rate = summary['images_with_detections'] / validation_results['test_images_count']
        if detection_rate > 0.7:
            print("üéØ High detection rate - model finds food in most images.")
        elif detection_rate > 0.5:
            print("‚úÖ Good detection rate - model is reliable.")
        else:
            print("üí° Consider adjusting confidence thresholds or more training data.")
        """Print comprehensive results from full training"""
        if validation_results is None:
            print("‚ö†Ô∏è  No test images found for validation")
            return
            
        summary = validation_results['summary']
        
        print("üèÜ Full Training Results:")
        print(f"   üìö Training epochs: {epochs}")
        print(f"   üñºÔ∏è  Tested on: {validation_results['test_images_count']} images")
        print(f"   üéØ Average detections: {summary['avg_detections_per_image']:.1f}")
        print(f"   üíØ Average confidence: {summary['avg_max_confidence']:.3f}")
        print(f"   ‚úÖ Images with detections: {summary['images_with_detections']}/{validation_results['test_images_count']}")
        
        # Performance interpretation
        print("\nüìä Performance Analysis:")
        
        if summary['avg_max_confidence'] > 0.6:
            print("üåü Excellent confidence scores! Model is production-ready.")
        elif summary['avg_max_confidence'] > 0.4:
            print("üëç Good confidence scores. Model is working well.")
        else:
            print("üîÑ Consider training longer or adding more varied training data.")
            
        detection_rate = summary['images_with_detections'] / validation_results['test_images_count']
        if detection_rate > 0.7:
            print("üéØ High detection rate - model finds food in most images.")
        elif detection_rate > 0.5:
            print("‚úÖ Good detection rate - model is reliable.")
        else:
            print("üí° Consider adjusting confidence thresholds or more training data.")

def main():
    """Main entry point with enhanced command line interface"""
    parser = argparse.ArgumentParser(
        description="Train custom YOLO models for food detection (FIXED VERSION)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Check if everything is ready for training
  python scripts/train_custom_food_model.py --mode check_setup
  
  # Quick test (5-15 minutes) - validates your setup
  python scripts/train_custom_food_model.py --mode quick_test
  
  # Full training with smart labeling (1-3 hours)
  python scripts/train_custom_food_model.py --mode full_training --epochs 50
  
  # Full training using existing images with custom epochs and dataset type
  python scripts/train_custom_food_model.py --mode full_training --dataset existing --epochs 75
  
  # Train segmentation model for precise food boundaries
  python scripts/train_custom_food_model.py --mode segmentation --epochs 50
  
  # Extended training for best results (2-6 hours)
  python scripts/train_custom_food_model.py --mode full_training --epochs 100
        """
    )
    
    parser.add_argument(
        '--mode',
        choices=['check_setup', 'quick_test', 'full_training', 'segmentation'],
        required=True,
        help='What to do: check_setup, quick_test, full_training, or segmentation'
    )
    
    parser.add_argument(
        '--epochs',
        type=int,
        default=None,
        help='Number of training epochs (default: 5 for quick_test, 50 for full_training)'
    )
    
    parser.add_argument(
        '--dataset',
        choices=['sample', 'existing', 'smart'],
        default='smart',
        help='Dataset type to use for training (sample, existing, or smart)'
    )
    
    args = parser.parse_args()
    
    # Create and run the orchestrator
    orchestrator = TrainingOrchestrator()
    
    try:
        if args.mode == 'check_setup':
            setup_ok = orchestrator.check_setup()
            if setup_ok:
                print("\nüí° Next: python scripts/train_custom_food_model.py --mode quick_test")
            
        elif args.mode == 'quick_test':
            epochs = args.epochs or 5  # Reduced for faster testing
            model, results = orchestrator.quick_test_training(epochs=epochs)
            
        elif args.mode == 'full_training':
            epochs = args.epochs or 50
            dataset_type = args.dataset or 'smart'
            model, results = orchestrator.full_training(epochs=epochs, dataset_type=dataset_type)
            
        elif args.mode == 'segmentation':
            epochs = args.epochs or 50
            model, results = orchestrator.segmentation_training(epochs=epochs)
            
    except KeyboardInterrupt:
        print("\n\n‚è∏Ô∏è  Training interrupted by user")
        print("üí° Training progress is saved - you can resume later")
        
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        print("üí° Try running --mode check_setup to diagnose issues")
        
    finally:
        # Calculate and display total time
        end_time = datetime.now()
        duration = end_time - orchestrator.start_time
        
        hours, remainder = divmod(duration.total_seconds(), 3600)
        minutes, seconds = divmod(remainder, 60)
        
        print(f"\n‚è±Ô∏è  Total time: {int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}")

if __name__ == "__main__":
    main()