# Food Segmentation Pipeline - Project Overview

Hey team! Let me break down what I've built here

## What This Project Does

Basically, I've created an AI system that can look at photos of food and tell you:
- **What food items are in the image** (apple, pizza, sandwich, etc.)
- **How much of each food** (portion sizes)

## The Tech Stack I'm Using

**ğŸ¯ YOLO Models** - These are the workhorses for detecting food items. Fast and reliable (5-10 seconds per image)
- YOLOv8, YOLOv9, YOLOv10 variants
- Both detection and segmentation versions
- Different sizes (nano for speed, larger for accuracy)

**ğŸ¨ SAM2 (Segment Anything Model 2)** - This gives us food outlines
- Currently slow (that 10+ minute issue we need to fix)
- Can do interactive segmentation (click on food items)

**ğŸ”§ Combined Pipeline** - The best of both worlds
- YOLO finds the food quickly
- SAM2 makes the masks super precise
- Nutrition database calculates calories/nutrients

## What I've Built So Far

### ğŸ“ Project Structure
```
â”œâ”€â”€ src/models/           # Core AI models
â”œâ”€â”€ scripts/             # Ready-to-use processing scripts  
â”œâ”€â”€ config/              # Configuration files
â”œâ”€â”€ data/               # Input images, models, results
â”œâ”€â”€ tests/              # Testing framework
â””â”€â”€ notebooks/          # Jupyter demos and experiments
```

### ğŸ“ Complete Project Structure
```
<<<<<<< HEAD
[FOLDER] E:\food_segmentation_pipeline
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Executive_Demo_20250611_015010
â”‚   â”œâ”€â”€ Executive_Demo_Report.html
â”‚   â”œâ”€â”€ comparison_results
â”‚   â”œâ”€â”€ detection_results
â”‚   â””â”€â”€ original_images
â”œâ”€â”€ README.md
â”œâ”€â”€ Report1.docx
â”œâ”€â”€ Report1.md
â”œâ”€â”€ Report1.pdf
â”œâ”€â”€ Report2.md
â”œâ”€â”€ Report3.md
â”œâ”€â”€ complete_training_run.py
â”œâ”€â”€ config
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ database_config.yaml
â”‚   â”œâ”€â”€ dataset_config.yaml
â”‚   â”œâ”€â”€ metadata_config.yaml
â”‚   â”œâ”€â”€ models.yaml
â”‚   â”œâ”€â”€ pipeline_config.yaml
â”‚   â”œâ”€â”€ training_config.yaml
â”‚   â””â”€â”€ training_config.yaml.backup
â”œâ”€â”€ create_achievement_demo.py
â”œâ”€â”€ create_visual_demo.py
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ databases
â”‚   â”‚   â”œâ”€â”€ cuisine_mapping
â”‚   â”‚   â”œâ”€â”€ food_taxonomy
â”‚   â”‚   â””â”€â”€ nutrition
â”‚   â”‚       â”œâ”€â”€ nutrition_expanded.db
â”‚   â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ food_training
â”‚   â”‚   â”œâ”€â”€ food_dataset.yaml
â”‚   â”‚   â”œâ”€â”€ images
â”‚   â”‚   â”‚   â”œâ”€â”€ train
â”‚   â”‚   â”‚   â””â”€â”€ val
â”‚   â”‚   â””â”€â”€ labels
â”‚   â”‚       â”œâ”€â”€ train
â”‚   â”‚       â””â”€â”€ val
â”‚   â”œâ”€â”€ input
â”‚   â”‚   â”œâ”€â”€ TRAINING_IMAGES_GUIDE.md
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ custom_food_detection.pt
â”‚   â”‚   â”œâ”€â”€ custom_food_detection_working.pt
â”‚   â”‚   â”œâ”€â”€ metadata_models
â”‚   â”‚   â”‚   â””â”€â”€ food101
â”‚   â”‚   â”‚       â”œâ”€â”€ model.safetensors
â”‚   â”‚   â”œâ”€â”€ sam2.1_hiera_base_plus.pt
â”‚   â”‚   â””â”€â”€ yolo_food_v8.pt
â”‚   â”œâ”€â”€ output
â”‚   â”‚   â”œâ”€â”€ achievement_demo
â”‚   â”‚   â”‚   â””â”€â”€ batch_testing_20250611_014128
â”‚   â”‚   â”œâ”€â”€ batch_comparison_report_20250605_143331.html
â”‚   â”‚   â”œâ”€â”€ batch_comparison_report_20250605_153847.html
â”‚   â”‚   â”œâ”€â”€ batch_model_comparison
â”‚   â”‚   â”‚   â”œâ”€â”€ batch_comparison_report_20250605_124545.html
â”‚   â”‚   â”œâ”€â”€ batch_results_20250605_153847.xlsx
â”‚   â”‚   â”œâ”€â”€ comparison_report_20250605_152817.html
â”‚   â”‚   â”œâ”€â”€ comparisons
â”‚   â”‚   â”œâ”€â”€ confidence_analysis_20250605_151710.csv
â”‚   â”‚   â”œâ”€â”€ confidence_analysis_20250605_152056.csv
â”‚   â”‚   â”œâ”€â”€ confidence_analysis_20250605_152212.csv
â”‚   â”‚   â”œâ”€â”€ confidence_analysis_20250605_152342.csv
â”‚   â”‚   â”œâ”€â”€ confidence_analysis_20250605_152817.csv
â”‚   â”‚   â”œâ”€â”€ custom_model_comparison
â”‚   â”‚   â”‚   â”œâ”€â”€ comparison_report_20250611_012842.html
â”‚   â”‚   â”‚   â”œâ”€â”€ confidence_analysis_20250611_012842.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ detailed_detections_20250611_012842.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ model_comparison_20250611_012842.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ model_comparison_20250611_012842.xlsx
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov10n
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8m-seg
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8n
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8n-oiv7
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8n-seg
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8n-world
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8s
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8s-seg
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov9n
â”‚   â”‚   â”‚   â””â”€â”€ yolov9s
â”‚   â”‚   â”œâ”€â”€ custom_tests
â”‚   â”‚   â”œâ”€â”€ custom_vs_pretrained
â”‚   â”‚   â”‚   â”œâ”€â”€ batch_comparison_report_20250611_013912.html
â”‚   â”‚   â”‚   â”œâ”€â”€ batch_results_20250611_013912.xlsx
â”‚   â”‚   â”‚   â”œâ”€â”€ detailed_results_20250611_013912.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ model_summary_20250611_013912.csv
â”‚   â”‚   â”‚   â””â”€â”€ per_image_comparison_20250611_013912.csv
â”‚   â”‚   â”œâ”€â”€ detailed_detections_20250605_151710.csv
â”‚   â”‚   â”œâ”€â”€ detailed_detections_20250605_152056.csv
â”‚   â”‚   â”œâ”€â”€ detailed_detections_20250605_152212.csv
â”‚   â”‚   â”œâ”€â”€ detailed_detections_20250605_152342.csv
â”‚   â”‚   â”œâ”€â”€ detailed_detections_20250605_152817.csv
â”‚   â”‚   â”œâ”€â”€ detailed_results_20250605_143331.csv
â”‚   â”‚   â”œâ”€â”€ detailed_results_20250605_153847.csv
â”‚   â”‚   â”œâ”€â”€ ingredient_counts
â”‚   â”‚   â”œâ”€â”€ metadata_results
â”‚   â”‚   â”œâ”€â”€ model_comparison
â”‚   â”‚   â”‚   â”œâ”€â”€ comparison_report_20250605_124948.html
â”‚   â”‚   â”‚   â”œâ”€â”€ model_comparison_report_20250605_123408.html
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov10n
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8m-seg
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8n
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8n-oiv7
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8n-seg
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8n-world
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8s
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov8s-seg
â”‚   â”‚   â”‚   â”œâ”€â”€ yolov9n
â”‚   â”‚   â”‚   â””â”€â”€ yolov9s
â”‚   â”‚   â”œâ”€â”€ model_comparison_20250605_151710.csv
â”‚   â”‚   â”œâ”€â”€ model_comparison_20250605_152056.csv
â”‚   â”‚   â”œâ”€â”€ model_comparison_20250605_152212.csv
â”‚   â”‚   â”œâ”€â”€ model_comparison_20250605_152342.csv
â”‚   â”‚   â”œâ”€â”€ model_comparison_20250605_152817.csv
â”‚   â”‚   â”œâ”€â”€ model_comparison_20250605_152817.xlsx
â”‚   â”‚   â”œâ”€â”€ model_summary_20250605_143331.csv
â”‚   â”‚   â”œâ”€â”€ model_summary_20250605_153847.csv
â”‚   â”‚   â”œâ”€â”€ per_image_comparison_20250605_143331.csv
â”‚   â”‚   â”œâ”€â”€ per_image_comparison_20250605_153847.csv
â”‚   â”‚   â”œâ”€â”€ yolo_results
â”‚   â”‚   â”‚   â”œâ”€â”€ batch_reports
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ dashboard_20250605_093544.html
â”‚   â”‚   â”‚   â”œâ”€â”€ image1_results_viewer.html
â”‚   â”‚   â”‚   â””â”€â”€ visualizations
â”‚   â”‚   â”œâ”€â”€ yolov10n
â”‚   â”‚   â”œâ”€â”€ yolov8m-seg
â”‚   â”‚   â”œâ”€â”€ yolov8n
â”‚   â”‚   â”œâ”€â”€ yolov8n-oiv7
â”‚   â”‚   â”œâ”€â”€ yolov8n-seg
â”‚   â”‚   â”œâ”€â”€ yolov8n-world
â”‚   â”‚   â”œâ”€â”€ yolov8s
â”‚   â”‚   â”œâ”€â”€ yolov8s-seg
â”‚   â”‚   â”œâ”€â”€ yolov9n
â”‚   â”‚   â””â”€â”€ yolov9s
â”‚   â”œâ”€â”€ trained_models
â”‚   â”‚   â”œâ”€â”€ experiments
â”‚   â”‚   â”œâ”€â”€ food_detection_20250610_205434
â”‚   â”‚   â”‚   â”œâ”€â”€ best.pt
â”‚   â”‚   â”‚   â””â”€â”€ training_metadata.yaml
â”‚   â”‚   â”œâ”€â”€ food_detection_20250611_010817
â”‚   â”‚   â”‚   â”œâ”€â”€ best.pt
â”‚   â”‚   â”‚   â””â”€â”€ training_metadata.yaml
â”‚   â”‚   â””â”€â”€ food_detection_20250612_144148
â”‚   â”‚       â”œâ”€â”€ best.pt
â”‚   â”‚       â””â”€â”€ training_metadata.yaml
â”‚   â””â”€â”€ training
â”‚       â”œâ”€â”€ annotations
â”‚       â”œâ”€â”€ food_training
â”‚       â”‚   â”œâ”€â”€ existing_images_dataset.yaml
â”‚       â”‚   â”œâ”€â”€ food_dataset.yaml
â”‚       â”‚   â”œâ”€â”€ food_segmentation_dataset.yaml
â”‚       â”‚   â”œâ”€â”€ images
â”‚       â”‚   â”‚   â”œâ”€â”€ train
â”‚       â”‚   â”‚   â””â”€â”€ val
â”‚       â”‚   â””â”€â”€ labels
â”‚       â”‚       â”œâ”€â”€ train
â”‚       â”‚       â”œâ”€â”€ train.cache
â”‚       â”‚       â”œâ”€â”€ val
â”‚       â”‚       â””â”€â”€ val.cache
â”‚       â”œâ”€â”€ raw_datasets
â”‚       â””â”€â”€ splits
â”œâ”€â”€ encoding_utils.py
â”œâ”€â”€ enhanced_batch_tester.py
â”œâ”€â”€ enhanced_single_image_tester.py
â”œâ”€â”€ fast_test.py
â”œâ”€â”€ fix_batch_size_issue.py
â”œâ”€â”€ fix_device_issue.py
â”œâ”€â”€ fix_imports.py
â”œâ”€â”€ fix_segmentation_dataset.py
â”œâ”€â”€ fix_training_issues.py
â”œâ”€â”€ fix_training_issues_windows.py
â”œâ”€â”€ fix_unicode.py
â”œâ”€â”€ food_training_runs
â”‚   â”œâ”€â”€ food_model_20250607_2019
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â”œâ”€â”€ results.csv
â”‚   â”‚   â””â”€â”€ weights
â”‚   â”‚       â”œâ”€â”€ best.pt
â”‚   â”‚       â””â”€â”€ last.pt
â”‚   â”œâ”€â”€ food_model_20250610_2109
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â”œâ”€â”€ results.csv
â”‚   â”‚   â””â”€â”€ weights
â”‚   â”‚       â”œâ”€â”€ best.pt
â”‚   â”‚       â””â”€â”€ last.pt
â”‚   â”œâ”€â”€ food_model_20250610_2243
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â”œâ”€â”€ results.csv
â”‚   â”‚   â””â”€â”€ weights
â”‚   â”‚       â”œâ”€â”€ best.pt
â”‚   â”‚       â””â”€â”€ last.pt
â”‚   â”œâ”€â”€ food_model_20250610_2346
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â”œâ”€â”€ results.csv
â”‚   â”‚   â””â”€â”€ weights
â”‚   â”‚       â”œâ”€â”€ best.pt
â”‚   â”‚       â””â”€â”€ last.pt
â”‚   â”œâ”€â”€ food_model_20250612_1317
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â”œâ”€â”€ results.csv
â”‚   â”‚   â””â”€â”€ weights
â”‚   â”‚       â”œâ”€â”€ best.pt
â”‚   â”‚       â””â”€â”€ last.pt
â”‚   â”œâ”€â”€ food_segmentation_20250610_2200_segmentation
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â””â”€â”€ weights
â”‚   â”œâ”€â”€ food_segmentation_20250610_2204_segmentation
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â””â”€â”€ weights
â”‚   â”œâ”€â”€ quick_test_0607_2007
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â””â”€â”€ weights
â”‚   â”œâ”€â”€ quick_test_0610_2029
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â””â”€â”€ weights
â”‚   â”œâ”€â”€ quick_test_0610_2032
â”‚   â”‚   â”œâ”€â”€ args.yaml
â”‚   â”‚   â””â”€â”€ weights
â”‚   â””â”€â”€ quick_test_0610_2046
â”‚       â”œâ”€â”€ args.yaml
â”‚       â”œâ”€â”€ results.csv
â”‚       â””â”€â”€ weights
â”‚           â”œâ”€â”€ best.pt
â”‚           â””â”€â”€ last.pt
â”œâ”€â”€ get-pip.py
â”œâ”€â”€ hybrid_food_detection.py
â”œâ”€â”€ hybrid_results
â”œâ”€â”€ improved_hybrid_detection.py
â”œâ”€â”€ improved_results
â”œâ”€â”€ logs
â”‚   â”œâ”€â”€ training_session_20250610_205724
â”‚   â”œâ”€â”€ training_session_20250610_205858
â”‚   â”œâ”€â”€ training_session_20250610_210150
â”‚   â”œâ”€â”€ training_session_20250610_210658
â”‚   â”œâ”€â”€ training_session_20250610_210702
â”‚   â””â”€â”€ training_session_20250610_210714
=======
food_segmentation_pipeline
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ config
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ models.yaml
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ input
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ sam2.1_hiera_base_plus.pt
â”‚   â”‚   â””â”€â”€ yolo_food_v8.pt
â”‚   â””â”€â”€ output
â”‚       â”œâ”€â”€ batch_comparison_report_20250605_143331.html
â”‚       â”œâ”€â”€ batch_comparison_report_20250605_153847.html
â”‚       â”œâ”€â”€ batch_model_comparison
â”‚       â”‚   â”œâ”€â”€ batch_comparison_report_20250605_124545.html
â”‚       â”œâ”€â”€ batch_results_20250605_153847.xlsx
â”‚       â”œâ”€â”€ comparison_report_20250605_152817.html
â”‚       â”œâ”€â”€ confidence_analysis_20250605_151710.csv
â”‚       â”œâ”€â”€ confidence_analysis_20250605_152056.csv
â”‚       â”œâ”€â”€ confidence_analysis_20250605_152212.csv
â”‚       â”œâ”€â”€ confidence_analysis_20250605_152342.csv
â”‚       â”œâ”€â”€ confidence_analysis_20250605_152817.csv
â”‚       â”œâ”€â”€ detailed_detections_20250605_151710.csv
â”‚       â”œâ”€â”€ detailed_detections_20250605_152056.csv
â”‚       â”œâ”€â”€ detailed_detections_20250605_152212.csv
â”‚       â”œâ”€â”€ detailed_detections_20250605_152342.csv
â”‚       â”œâ”€â”€ detailed_detections_20250605_152817.csv
â”‚       â”œâ”€â”€ detailed_results_20250605_143331.csv
â”‚       â”œâ”€â”€ detailed_results_20250605_153847.csv
â”‚       â”œâ”€â”€ model_comparison
â”‚       â”‚   â”œâ”€â”€ comparison_report_20250605_124948.html
â”‚       â”‚   â”œâ”€â”€ model_comparison_report_20250605_123408.html
â”‚       â”‚   â”œâ”€â”€ yolov10n
â”‚       â”‚   â”œâ”€â”€ yolov8m-seg
â”‚       â”‚   â”œâ”€â”€ yolov8n
â”‚       â”‚   â”œâ”€â”€ yolov8n-oiv7
â”‚       â”‚   â”œâ”€â”€ yolov8n-seg
â”‚       â”‚   â”œâ”€â”€ yolov8n-world
â”‚       â”‚   â”œâ”€â”€ yolov8s
â”‚       â”‚   â”œâ”€â”€ yolov8s-seg
â”‚       â”‚   â”œâ”€â”€ yolov9n
â”‚       â”‚   â””â”€â”€ yolov9s
â”‚       â”œâ”€â”€ model_comparison_20250605_151710.csv
â”‚       â”œâ”€â”€ model_comparison_20250605_152056.csv
â”‚       â”œâ”€â”€ model_comparison_20250605_152212.csv
â”‚       â”œâ”€â”€ model_comparison_20250605_152342.csv
â”‚       â”œâ”€â”€ model_comparison_20250605_152817.csv
â”‚       â”œâ”€â”€ model_comparison_20250605_152817.xlsx
â”‚       â”œâ”€â”€ model_summary_20250605_143331.csv
â”‚       â”œâ”€â”€ model_summary_20250605_153847.csv
â”‚       â”œâ”€â”€ per_image_comparison_20250605_143331.csv
â”‚       â”œâ”€â”€ per_image_comparison_20250605_153847.csv
â”‚       â”œâ”€â”€ yolo_results
â”‚       â”‚   â”œâ”€â”€ batch_reports
â”‚       â”‚   â”‚   â””â”€â”€ dashboard_20250605_093544.html
â”‚       â”‚   â”œâ”€â”€ image1_results_viewer.html
â”‚       â”‚   â””â”€â”€ visualizations
â”‚       â”œâ”€â”€ yolov10n
â”‚       â”œâ”€â”€ yolov8m-seg
â”‚       â”œâ”€â”€ yolov8n
â”‚       â”œâ”€â”€ yolov8n-oiv7
â”‚       â”œâ”€â”€ yolov8n-seg
â”‚       â”œâ”€â”€ yolov8n-world
â”‚       â”œâ”€â”€ yolov8s
â”‚       â”œâ”€â”€ yolov8s-seg
â”‚       â”œâ”€â”€ yolov9n
â”‚       â””â”€â”€ yolov9s
â”œâ”€â”€ enhanced_batch_tester.py
â”œâ”€â”€ enhanced_single_image_tester.py
â”œâ”€â”€ fast_test.py
â”œâ”€â”€ fix_imports.py
>>>>>>> 82a126b (Complete Meal or Portion integration)
â”œâ”€â”€ model_comparison_enhanced.py
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ demo.ipynb
â”‚   â””â”€â”€ experiments.ipynb
â”œâ”€â”€ output_directory
â”‚   â”œâ”€â”€ confidence_analysis_20250605_154119.csv
â”‚   â”œâ”€â”€ detailed_detections_20250605_154119.csv
â”‚   â”œâ”€â”€ model_comparison_report_20250605_154119.html
â”‚   â”œâ”€â”€ model_summary_20250605_154119.csv
â”‚   â””â”€â”€ single_image_test_20250605_154119.xlsx
â”œâ”€â”€ print_directory_tree.py
<<<<<<< HEAD
â”œâ”€â”€ run_with_logging.py
â”œâ”€â”€ runpod
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ start_server.sh
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ batch_process_yolo.py
â”‚   â”œâ”€â”€ build_all_databases.py
â”‚   â”œâ”€â”€ ceo_demo_counter.py
â”‚   â”œâ”€â”€ compare_ingredient_detection.py
â”‚   â”œâ”€â”€ compare_model_results.py
â”‚   â”œâ”€â”€ detect_and_count_ingredients.py
â”‚   â”œâ”€â”€ diagnose_model_detection.py
â”‚   â”œâ”€â”€ enhanced_ingredient_counter.py
=======
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ batch_process_yolo.py
>>>>>>> 82a126b (Complete Meal or Portion integration)
â”‚   â”œâ”€â”€ generate_tree.py
â”‚   â”œâ”€â”€ process_batch.py
â”‚   â”œâ”€â”€ process_single_image.py
â”‚   â”œâ”€â”€ process_single_yolo.py
<<<<<<< HEAD
â”‚   â”œâ”€â”€ process_with_custom_model.py
â”‚   â”œâ”€â”€ process_with_metadata.py
â”‚   â”œâ”€â”€ quick_ingredient_demo.py
â”‚   â”œâ”€â”€ quick_start_training.py
â”‚   â”œâ”€â”€ runpod_launcher.py
â”‚   â”œâ”€â”€ setup_metadata_system.py
â”‚   â”œâ”€â”€ setup_models.py
â”‚   â”œâ”€â”€ simple_batch_yolo.py
â”‚   â”œâ”€â”€ train_custom_food_model.py
â”‚   â”œâ”€â”€ train_ingredient_counter.py
â”‚   â”œâ”€â”€ train_yolo_food.py
â”‚   â””â”€â”€ training_scripts
â”œâ”€â”€ setup.py
â”œâ”€â”€ setup_training.py
=======
â”‚   â”œâ”€â”€ setup_models.py
â”‚   â”œâ”€â”€ simple_batch_yolo.py
â”‚   â””â”€â”€ train_yolo_food.py
â”œâ”€â”€ setup.py
>>>>>>> 82a126b (Complete Meal or Portion integration)
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ .py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â””â”€â”€ __init__.cpython-312.pyc
â”‚   â”œâ”€â”€ annotation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ coco_converter.py
â”‚   â”‚   â””â”€â”€ quality_controller.py
â”‚   â”œâ”€â”€ api
â”‚   â”‚   â”œâ”€â”€ __init__.py
<<<<<<< HEAD
â”‚   â”‚   â”œâ”€â”€ fastapi_server.py
â”‚   â”‚   â””â”€â”€ metadata_api.py
â”‚   â”œâ”€â”€ databases
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ allergen_database.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ build_nutrition_db.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ food_taxonomy.cpython-312.pyc
â”‚   â”‚   â”‚   â””â”€â”€ nutrition_database.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ allergen_database.py
â”‚   â”‚   â”œâ”€â”€ build_nutrition_db.py
â”‚   â”‚   â”œâ”€â”€ food_taxonomy.py
â”‚   â”‚   â””â”€â”€ nutrition_database.py
â”‚   â”œâ”€â”€ evaluation
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ metadata
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ cuisine_identifier.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ food_classifier.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ metadata_aggregator.cpython-312.pyc
â”‚   â”‚   â”‚   â””â”€â”€ portion_estimator.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ cuisine_identifier.py
â”‚   â”‚   â”œâ”€â”€ food_classifier.py
â”‚   â”‚   â”œâ”€â”€ ingredient_detector.py
â”‚   â”‚   â”œâ”€â”€ metadata_aggregator.py
â”‚   â”‚   â””â”€â”€ portion_estimator.py
=======
â”‚   â”‚   â””â”€â”€ fastapi_server.py
>>>>>>> 82a126b (Complete Meal or Portion integration)
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ combined_pipeline.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ fast_segmentation.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ fast_yolo_segmentation.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ sam2_predictor.cpython-312.pyc
â”‚   â”‚   â”‚   â””â”€â”€ yolo_detector.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ combined_pipeline.py
â”‚   â”‚   â”œâ”€â”€ fast_segmentation.py
â”‚   â”‚   â”œâ”€â”€ fast_yolo_segmentation.py
â”‚   â”‚   â”œâ”€â”€ sam2_predictor.py
â”‚   â”‚   â””â”€â”€ yolo_detector.py
<<<<<<< HEAD
â”‚   â”œâ”€â”€ pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.cpython-312.pyc
â”‚   â”‚   â”‚   â””â”€â”€ output_formatter.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ metadata_pipeline.py
â”‚   â”‚   â””â”€â”€ output_formatter.py
=======
>>>>>>> 82a126b (Complete Meal or Portion integration)
â”‚   â”œâ”€â”€ preprocessing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.cpython-312.pyc
â”‚   â”‚   â”‚   â””â”€â”€ food_preprocessor.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ food_preprocessor.py
â”‚   â”‚   â””â”€â”€ image_enhancer.py
<<<<<<< HEAD
â”‚   â”œâ”€â”€ training
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.cpython-312.pyc
â”‚   â”‚   â”‚   â”œâ”€â”€ food_dataset_preparer.cpython-312.pyc
â”‚   â”‚   â”‚   â””â”€â”€ food_yolo_trainer.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ food_dataset_preparer.py
â”‚   â”‚   â””â”€â”€ food_yolo_trainer.py
=======
>>>>>>> 82a126b (Complete Meal or Portion integration)
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ __pycache__
â”‚       â”‚   â”œâ”€â”€ __init__.cpython-312.pyc
â”‚       â”‚   â”œâ”€â”€ nutrition_db.cpython-312.pyc
â”‚       â”‚   â””â”€â”€ visualization.cpython-312.pyc
â”‚       â”œâ”€â”€ file_utils.py
â”‚       â”œâ”€â”€ nutrition_db.py
â”‚       â””â”€â”€ visualization.py
â”œâ”€â”€ test_all_models.py
â”œâ”€â”€ test_batch_enhanced.py
â”œâ”€â”€ test_sam2.py
â”œâ”€â”€ test_simple.py
â”œâ”€â”€ test_single_image_all_models.py
â”œâ”€â”€ test_single_image_enhanced.py
â”œâ”€â”€ test_yolo_setup.py
â”œâ”€â”€ test_yolo_simple.py
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â”œâ”€â”€ test_sam2.py
â”‚   â””â”€â”€ test_yolo.py
<<<<<<< HEAD
â”œâ”€â”€ train_detection_working.py
â”œâ”€â”€ train_segmentation_direct.py
â”œâ”€â”€ train_segmentation_fixed.py
â”œâ”€â”€ train_segmentation_minimal.py
=======
>>>>>>> 82a126b (Complete Meal or Portion integration)
â”œâ”€â”€ view_results.py
â”œâ”€â”€ weights
â”‚   â”œâ”€â”€ yolov5s.pt
â”‚   â”œâ”€â”€ yolov5su.pt
â”‚   â””â”€â”€ yolov8n-oiv7.pt
<<<<<<< HEAD
â”œâ”€â”€ working_detection
â”‚   â””â”€â”€ food_detection_working
â”‚       â”œâ”€â”€ args.yaml
â”‚       â”œâ”€â”€ results.csv
â”‚       â””â”€â”€ weights
â”‚           â”œâ”€â”€ best.pt
â”‚           â””â”€â”€ last.pt
â”œâ”€â”€ yolov10n.pt
â”œâ”€â”€ yolov8m-seg.pt
â”œâ”€â”€ yolov8m.pt
â”œâ”€â”€ yolov8n-cls.pt
=======
â”œâ”€â”€ yolov10n.pt
â”œâ”€â”€ yolov8m-seg.pt
>>>>>>> 82a126b (Complete Meal or Portion integration)
â”œâ”€â”€ yolov8n-seg.pt
â”œâ”€â”€ yolov8n.pt
â”œâ”€â”€ yolov8s-seg.pt
â”œâ”€â”€ yolov8s.pt
â””â”€â”€ yolov9s.pt
```

## Project Architecture

```mermaid
graph TD
    %% Root Project
    A[ğŸ• Food Segmentation Pipeline] 
    
    %% Configuration Layer
    A --> B[âš™ï¸ Configuration]
    B --> B1[config/config.yaml]
    B --> B2[config/models.yaml]
    
    %% Input Data Flow
    A --> C[ğŸ“¸ Input Images]
    C --> C1[data/input/]
    
    %% AI Models Layer
    A --> D[ğŸ¤– AI Models]
    D --> D1[data/models/sam2.1_hiera_base_plus.pt]
    D --> D2[data/models/yolo_food_v8.pt]
    D --> D3[weights/yolov5s.pt]
    D --> D4[yolov8n.pt, yolov9s.pt, etc.]
    
    %% Core Processing Engine
    A --> E[ğŸ”§ Core Processing]
    E --> E1[src/models/yolo_detector.py]
    E --> E2[src/models/sam2_predictor.py]
    E --> E3[src/models/combined_pipeline.py]
    E --> E4[src/models/fast_yolo_segmentation.py]
    E --> E5[src/preprocessing/food_preprocessor.py]
    E --> E6[src/utils/nutrition_db.py]
    E --> E7[src/utils/visualization.py]
    
    %% Processing Scripts (Entry Points)
    A --> F[ğŸš€ Processing Scripts]
    F --> F1[enhanced_single_image_tester.py]
    F --> F2[enhanced_batch_tester.py]
    F --> F3[model_comparison_enhanced.py]
    F --> F4[scripts/process_single_yolo.py]
    F --> F5[scripts/batch_process_yolo.py]
    F --> F6[test_all_models.py]
    
    %% Results & Output
    A --> G[ğŸ“Š Output Results]
    G --> G1[data/output/batch_comparison_reports]
    G --> G2[data/output/model_comparison/]
    G --> G3[data/output/yolo_results/]
    G --> G4[output_directory/]
    G1 --> G1a[HTML Reports]
    G1 --> G1b[Excel Files]
    G1 --> G1c[CSV Analysis]
    G2 --> G2a[yolov8n, yolov9s, etc.]
    G3 --> G3a[batch_reports/]
    G3 --> G3b[visualizations/]
    
    %% Development & Testing
    A --> H[ğŸ§ª Development]
    H --> H1[notebooks/demo.ipynb]
    H --> H2[notebooks/experiments.ipynb]
    H --> H3[tests/test_pipeline.py]
    H --> H4[tests/test_yolo.py]
    H --> H5[tests/test_sam2.py]
    
    %% API & Deployment
    A --> I[ğŸŒ API Layer]
    I --> I1[src/api/fastapi_server.py]
    
    %% Data Flow Connections
    C1 -.-> F1
    C1 -.-> F2
    F1 -.-> E3
    F2 -.-> E3
    F3 -.-> E1
    E1 -.-> D2
    E2 -.-> D1
    E3 -.-> G1
    E3 -.-> G2
    B1 -.-> E3
    B2 -.-> E3

```

``` mermaid
flowchart TB
    %% External Interfaces
    CLI["CLI / Notebook"]:::external

    %% Orchestration Layer
    subgraph "Orchestration Layer"
        direction TB
        SingleImage["Process Single Image"]:::orchestration
        Batch["Process Batch"]:::orchestration
        TrainYOLO["Train YOLO"]:::orchestration
        EnhancedSingle["Enhanced Single Tester"]:::orchestration
        EnhancedBatch["Enhanced Batch Tester"]:::orchestration
        ModelComp["Model Comparison"]:::orchestration
        FastTest["Fast Test Entry"]:::orchestration
        ViewResults["View Results"]:::orchestration
        FastAPI["FastAPI Server"]:::orchestration
        ConfigMain["config/config.yaml"]:::orchestration
        ConfigModels["config/models.yaml"]:::orchestration
    end

    %% Core Pipeline
    subgraph "Core Pipeline"
        direction TB
        FoodPreproc["Food Preprocessor"]:::processing
        ImageEnhancer["Image Enhancer"]:::processing
        YOLODet["YOLO Detector\n(v8/v9/v10)"]:::processing
        SAM2Pred["SAM2 Predictor"]:::processing
        CombinedPipe["Combined Pipeline"]:::processing
        FastYolo["Fast YOLO Segmentation"]:::processing
        FastSeg["Fast Segmentation"]:::processing
        NutritionCalc["Nutrition Calculator"]:::processing
        Visualization["Visualization Utilities"]:::processing
        FileUtils["File Utilities"]:::processing
    end

    %% Data Stores
    subgraph "Data Stores"
        direction TB
        InputImages(("Input Images")):::datastore
        DataModels(("Model Weights")):::datastore
        NutritionDB(("Nutrition DB")):::datastore
        OutputDefault(("Default Output")):::datastore
        OutputCustom(("Custom Output Directory")):::datastore
    end

    %% External to Orchestration
    CLI --> SingleImage
    CLI --> Batch
    CLI --> TrainYOLO
    CLI --> EnhancedSingle
    CLI --> EnhancedBatch
    CLI --> ModelComp
    CLI --> FastTest
    CLI --> ViewResults
    CLI --> FastAPI

    %% Configuration connections
    ConfigMain --> SingleImage
    ConfigMain --> Batch
    ConfigMain --> FastAPI
    ConfigModels --> YOLODet

    %% Orchestration to Core Pipeline
    SingleImage --> FoodPreproc
    Batch --> FoodPreproc
    FastAPI --> FoodPreproc
    ModelComp --> YOLODet

    %% Data flow in Core Pipeline
    InputImages --> FoodPreproc --> ImageEnhancer --> YOLODet
    DataModels --> YOLODet
    YOLODet --> SAM2Pred
    DataModels --> SAM2Pred
    SAM2Pred --> CombinedPipe
    CombinedPipe --> NutritionCalc
    NutritionDB --> NutritionCalc
    NutritionCalc --> Visualization --> FileUtils --> OutputDefault
    FileUtils --> OutputCustom

    %% Fast shortcuts branch
    YOLODet --> FastYolo --> CombinedPipe
    YOLODet --> FastSeg --> CombinedPipe

    %% Click Events
    click InputImages "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/tree/main/data/input/"
    click DataModels "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/tree/main/data/models/"
    click NutritionDB "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/data/nutrition_database.json"
    click FoodPreproc "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/preprocessing/food_preprocessor.py"
    click ImageEnhancer "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/preprocessing/image_enhancer.py"
    click YOLODet "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/models/yolo_detector.py"
    click SAM2Pred "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/models/sam2_predictor.py"
    click CombinedPipe "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/models/combined_pipeline.py"
    click FastYolo "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/models/fast_yolo_segmentation.py"
    click FastSeg "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/models/fast_segmentation.py"
    click NutritionCalc "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/utils/nutrition_db.py"
    click Visualization "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/utils/visualization.py"
    click FileUtils "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/utils/file_utils.py"
    click SingleImage "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/scripts/process_single_image.py"
    click Batch "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/scripts/process_batch.py"
    click TrainYOLO "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/scripts/train_yolo_food.py"
    click EnhancedSingle "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/enhanced_single_image_tester.py"
    click EnhancedBatch "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/enhanced_batch_tester.py"
    click ModelComp "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/model_comparison_enhanced.py"
    click FastTest "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/fast_test.py"
    click ViewResults "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/view_results.py"
    click ConfigMain "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/config/config.yaml"
    click ConfigModels "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/config/models.yaml"
    click FastAPI "https://github.com/arshnoor-singh-sohi/food-segmentation-pipeline/blob/main/src/api/fastapi_server.py"

    %% Styles
    classDef datastore fill:#ADD8E6,stroke:#333,stroke-width:1px
    classDef processing fill:#90EE90,stroke:#333,stroke-width:1px
    classDef orchestration fill:#FFA500,stroke:#333,stroke-width:1px
    classDef external fill:#DDA0DD,stroke:#333,stroke-width:1px

```


### ğŸš€ Key Features That Work Right Now

**1. Single Image Processing**
```bash
python scripts/process_single_yolo.py data/input/image1.jpg
```
- Analyzes one food photo in ~5-10 seconds
- Shows detected items with confidence scores
- Calculates nutrition info
- Creates nice visualizations

**2. Batch Processing** 
```bash
python scripts/batch_process_yolo.py --input-dir data/input
```
- Processes entire folders of images
- Progress bars and error handling
- Generates comprehensive HTML reports
- CSV exports for Excel analysis

**3. Model Comparison**
```bash
python test_all_models.py --input-dir data/input
```
- Tests 10+ different YOLO models
- Ranks them by performance
- Shows which works best for food images
- HTML dashboard with results

**4. Enhanced Testing Suite**
- Beautiful HTML reports with charts
- Confidence analysis across different thresholds  
- Detailed nutrition breakdowns
- Error handling and logging

## Current Status & What Works

âœ… **YOLO Food Detection** - Working well, still improving accuracy
âœ… **Nutrition Calculation** - Basic database working
âœ… **Batch Processing** - Can handle hundreds of images
âœ… **Model Comparison** - Helps pick the best models
âœ… **HTML Reports** - Nice visualizations and dashboards
âœ… **Configuration System** - Easy to tweak settings

âš ï¸ **SAM2 Integration** - Works but too slow (need to optimize)

## Sample Output

When you run it on a food image, you get:
```
ğŸ½ï¸ FOOD ANALYSIS RESULTS
ğŸ“¸ Image: pizza_slice.jpg
â±ï¸  Processing time: 3.2s
ğŸ” Items detected: 3
ğŸ Food items: 2
ğŸ½ï¸ Non-food items: 1

ğŸ¥— NUTRITION TOTALS:
   Calories: 420.5
   Protein: 18.2g
   Carbs: 45.1g
   Fat: 16.8g

ğŸ“‹ DETECTED ITEMS:
   1. ğŸ pizza (0.87 conf)
      â””â”€ ~380 cal, 120g
   2. ğŸ salad (0.72 conf)  
      â””â”€ ~40 cal, 80g
   3. ğŸ½ï¸ plate (0.91 conf)
```

## Output Data Available

All the processed results are saved in organized output folders:

**ğŸ“Š Data/Output Structure:**
- **CSV files** - Detailed nutrition data, confidence scores, detection summaries
- **Excel files** - Comprehensive analysis reports and comparisons
- **JSON files** - Raw detection data and metadata for each image
- **Segmented images** - Visual results with bounding boxes and labels
- **HTML reports** - Interactive dashboards and model comparisons
- **Batch results** - Summary statistics across multiple images
- **Individual results** - Detailed analysis for each processed image
- **Model comparison data** - Performance metrics across different YOLO variants

Everything is automatically organized by timestamp and model type for easy access and analysis.

## Commands I Use Most

```bash
# Quick single image test
python enhanced_single_image_tester.py data/input/image1.jpg output_directory

# Batch process a folder
python enhanced_batch_tester.py --input-dir data/input --output-dir data/output

# Compare all models
python model_comparison_enhanced.py --input-dir data/input --output-dir data/output

# Fast YOLO-only processing
python scripts/process_single_yolo.py data/input/image1.jpg --model-size s
```

## What's Next

1. **Fix SAM2 speed** - Currently the bottleneck

## To Get Started

1. Put some food images in `data/input/`
2. Run `python test_single_image_enhanced.py data/input/your_image.jpg output_directory` 
3. Check the HTML report that gets generated
4. Play around with different models and settings

The codebase is pretty modular - each component can work independently, so you can focus on whatever part interests you most!

